# Santander Customer Satisfaction

Projeto de classifica√ß√£o bin√°ria baseado na competi√ß√£o **Santander Customer Satisfaction** do Kaggle (2016).

## Vis√£o Geral

Este projeto utiliza como base o dataset da competi√ß√£o **Santander Customer Satisfaction**, disponibilizada no Kaggle em 2016. O objetivo original da competi√ß√£o √© identificar clientes insatisfeitos a partir de centenas de vari√°veis anonimizadas, permitindo que o banco possa agir de forma antecipada para reduzir churn.

A m√©trica oficial da competi√ß√£o √© a **√°rea sob a curva ROC (ROC_AUC)**, calculada a partir da probabilidade prevista para a vari√°vel **TARGET**, que indica se o cliente est√° satisfeito (`0`) ou insatisfeito (`1`).

üîó Link da competi√ß√£o:
https://www.kaggle.com/competitions/santander-customer-satisfaction

---

## Objetivo do Projeto

O objetivo deste projeto √© tratar o problema como uma **tarefa de classifica√ß√£o bin√°ria**, buscando identificar clientes insatisfeitos a partir das vari√°veis dispon√≠veis.

A partir das previs√µes dos modelos, √© constru√≠do um **cen√°rio hipot√©tico de neg√≥cio**, no qual s√£o simulados custos associados a a√ß√µes de reten√ß√£o e √† perda de clientes. Esses valores s√£o fict√≠cios e servem apenas para permitir a an√°lise sob a √≥tica de **maximiza√ß√£o do lucro esperado por cliente**.

Al√©m da predi√ß√£o, o projeto inclui an√°lises explorat√≥rias e t√©cnicas de redu√ß√£o de dimensionalidade e interpretabilidade, com foco em:

- Identificar fatores latentes por meio de An√°lise Fatorial Explorat√≥ria (EFA).

- Avaliar a explicabilidade do modelo para facilitar a comunica√ß√£o com stakeholders.

- Explorar cen√°rios hipot√©ticos de neg√≥cio, simulando custos associados √† reten√ß√£o e perda de clientes, permitindo an√°lise de lucro esperado por cliente.

---

## Modelos Avaliados

Foram avaliados os seguintes modelos de machine learning:

- Logistic Regression
- Random Forest
- XGBoost

Os modelos foram comparados em diferentes cen√°rios de pr√©-processamento:

- Baseline
- Sele√ß√£o de Features via agrupamento
- Redu√ß√£o de dimensionalidade com PCA
- An√°lise Fatorial (fatores e fatores combinados com PCA)

A avalia√ß√£o foi realizada por meio de valida√ß√£o cruzada, utilizando as m√©tricas ROC_AUC e PR_AUC, sendo esta √∫ltima especialmente relevante devido ao desbalanceamento da classe positiva.

---

## Conclus√£o sobre a Sele√ß√£o do Modelo

Com base nos resultados obtidos nos experimentos de valida√ß√£o cruzada, o modelo selecionado para dar continuidade ao projeto foi o **XGBoost**. Esse modelo apresentou os melhores valores de **ROC_AUC** e **PR_AUC** nos cen√°rios de *Baseline* e *Sele√ß√£o de Features*.

No cen√°rio em que o **PCA** foi utilizado como etapa de pr√©-processamento, observou-se uma queda de performance do XGBoost. Esse comportamento pode estar relacionado ao fato de o algoritmo utilizar √°rvores de decis√£o combinadas por *gradient boosting*, apresentando melhor desempenho quando as vari√°veis mant√™m maior distin√ß√£o e significado sem√¢ntico em sua forma original.

### Principais insights:

- **Nenhum ganho significativo**: Nenhuma das t√©cnicas de pr√©-processamento adicionais (sele√ß√£o de features avan√ßada, an√°lise fatorial) trouxe melhora real nas m√©tricas em rela√ß√£o ao modelo b√°sico.

- **An√°lise Fatorial**: Embora n√£o tenha aumentado desempenho ou estabilidade, permitiu maior interpretabilidade, facilitando a comunica√ß√£o de insights para stakeholders e auxiliando em pr√≥ximos passos, como a clusteriza√ß√£o de clientes.

- **Insight de neg√≥cio**: T√©cnicas de explicabilidade e redu√ß√£o de dimensionalidade podem ser √∫teis para relat√≥rios estrat√©gicos e tomada de decis√£o, mesmo que n√£o melhorem diretamente a performance do modelo.

---

## Pr√≥ximos Passos

- Avaliar outras m√©tricas como matriz de confus√£o, F1-score e m√©tricas espec√≠ficas de neg√≥cio.
- Realizar tuning de hiperpar√¢metros do XGBoost para maximizar performance.
- Explorar outras t√©cnicas de sele√ß√£o de features e fatores latentes para insights interpret√°veis.
- Testar robustez do modelo com diferentes splits e valida√ß√£o cruzada mais extensa.
- Aplicar clusteriza√ß√£o de clientes usando fatores identificados na EFA para segmenta√ß√£o estrat√©gica.

---

## Depend√™ncias

As bibliotecas utilizadas no projeto est√£o listadas no arquivo `requirements.txt`. Caso necess√°rio, podem ser instaladas manualmente:

```bash
pip install numpy
pip install seaborn
pip install scikit-learn
pip install scipy
pip install factor_analyzer
pip install matplotlib
pip install catboost
pip install graphviz
pip install plotly
pip install six
pip install shap-selection
````

---

## Refer√™ncia

Soraya Jimenez; Will Cukierski.
**Santander Customer Satisfaction**. Kaggle, 2016.
[https://www.kaggle.com/competitions/santander-customer-satisfaction](https://www.kaggle.com/competitions/santander-customer-satisfaction)
